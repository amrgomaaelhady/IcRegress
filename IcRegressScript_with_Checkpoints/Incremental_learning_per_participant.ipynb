{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c028b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d38a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,x,y,training_type):\n",
    "\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "        if training_type == 'classify':\n",
    "            self.y_train=torch.tensor(y,dtype=torch.int64)\n",
    "        elif training_type == 'regress':\n",
    "            self.y_train=torch.tensor(y,dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx],self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9801bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetCNN(nn.Module):\n",
    "    def __init__(self,dim_num,classes):\n",
    "        super(NetCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(dim_num, 64, kernel_size=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(p=0.3)\n",
    "        )\n",
    "        self.layer1_1 = nn.Sequential(\n",
    "            nn.Conv1d(64, 16, kernel_size=2),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(p=0.3)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(16, 8, kernel_size=3),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(p=0.3)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(8, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3)\n",
    "        )\n",
    "        \n",
    "        self.layer3_1 = nn.Sequential(\n",
    "            nn.Linear(48, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3)\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Linear(in_features=20, out_features=classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer1_1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer3_1(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef6d2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetLSTM(nn.Module):\n",
    "    def __init__(self,dim_num,classes):\n",
    "        super(NetLSTM, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.LSTM(input_size=dim_num,\n",
    "                            hidden_size=16,\n",
    "                            num_layers=3,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        \n",
    "        self.layer4 = nn.Linear(in_features=640, out_features=classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out, states = self.layer1(x)\n",
    "        out = out.reshape(out.size(0), -1)   # Flatten them for Many to one LSTM\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2794dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetTransf(nn.Module):\n",
    "    def __init__(self, dim_num: int, d_model: int, nhead: int, d_hid: int, \n",
    "                 nlayers: int, classes: int, dropout: float, batch_size: int):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "#         self.encoder = nn.Linear(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "#         self.dim_num = dim_num\n",
    "        self.decoder = nn.Linear(dim_num, classes)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "#         self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = src * math.sqrt(self.d_model)\n",
    "#         print(src.shape)\n",
    "        src = src.permute(2, 0, 1)\n",
    "#         print(src.shape)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "#         print(output.shape)\n",
    "        output = output.mean(0)\n",
    "#         print(output.shape)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "#     \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "#     return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81441cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_to_run(data_train, data_test, input_columns, mode, training_type, number_epochs, batch_size, learning_rate, fine_tuning,fine_tune_ckp_path, inference_only, inference_ckp_path, regress_type):\n",
    "\n",
    "    X_train = data_train[input_columns]\n",
    "    X_test = data_test[input_columns]\n",
    "    \n",
    "    if training_type == 'classify':\n",
    "        y_train = data_train.POIBuilding_new\n",
    "        y_test = data_test.POIBuilding_new\n",
    "        output_classes = 16\n",
    "        \n",
    "    elif training_type == 'regress':\n",
    "        y_train = data_train[['PoI_GT_centerLatAngle',\n",
    "                      'PoI_GT_visibleMinLatAngle','PoI_GT_visibleMaxLatAngle','PoI_GT_minLatAngle',\n",
    "                      'PoI_GT_maxLatAngle','PoI_GT_adjustedMinLatAngle','PoI_GT_adjustedMaxLatAngle']]\n",
    "        y_test = data_test[['PoI_GT_centerLatAngle',\n",
    "                    'PoI_GT_visibleMinLatAngle','PoI_GT_visibleMaxLatAngle','PoI_GT_minLatAngle',\n",
    "                    'PoI_GT_maxLatAngle','PoI_GT_adjustedMinLatAngle','PoI_GT_adjustedMaxLatAngle']]\n",
    "        output_classes = 1\n",
    "\n",
    "    if mode == 'CNN' or mode == 'Transformer':\n",
    "        X_train = (X_train.values.reshape(X_train.shape[0],X_train.shape[-1]//20,20))#.swapaxes(1,2)\n",
    "        X_test = (X_test.values.reshape(X_test.shape[0],X_test.shape[-1]//20,20))#.swapaxes(1,2)\n",
    "    \n",
    "    elif mode == 'LSTM':\n",
    "        X_train = (X_train.values.reshape(X_train.shape[0],X_train.shape[-1]//20,20)).swapaxes(1,2)\n",
    "        X_test = (X_test.values.reshape(X_test.shape[0],X_test.shape[-1]//20,20)).swapaxes(1,2)\n",
    "    \n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    \n",
    "    X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(\n",
    "       X_train, y_train, random_state=42, test_size=0.12\n",
    "    )\n",
    "    \n",
    "    print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)\n",
    "    print(\"#\"*80)\n",
    "    \n",
    "    if mode == 'Transformer':\n",
    "        ntokens = X_train.shape[1]  # size of vocabulary\n",
    "        emsize = 8  # embedding dimension\n",
    "        d_hid = 50  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "        nlayers = 6  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "        nhead = 8  # number of heads in nn.MultiheadAttention\n",
    "        dropout = 0.2  # dropout probability\n",
    "        net = NetTransf(ntokens, emsize, nhead, d_hid, nlayers, output_classes, dropout, batch_size)\n",
    "\n",
    "    if mode == 'CNN':\n",
    "        net = NetCNN(X_train.shape[1],classes=output_classes)\n",
    "    \n",
    "    elif mode == 'LSTM':\n",
    "        net = NetLSTM(X_train.shape[-1],classes=output_classes)\n",
    "    \n",
    "    print(net)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    # In[17]:\n",
    "    net.to(device)\n",
    "\n",
    "\n",
    "    def save_ckp(state, is_best,f_path):\n",
    "        torch.save(state, f_path)\n",
    "        if is_best:\n",
    "            best_fpath = 'best_model.pt'\n",
    "            shutil.copyfile(f_path, best_fpath)\n",
    "\n",
    "    def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "        checkpoint = torch.load(checkpoint_fpath)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        return model, optimizer, checkpoint['epoch']\n",
    "    \n",
    "    #padding nan values in X\n",
    "#     X_train = np.nan_to_num(X_train)\n",
    "#     X_test = np.nan_to_num(X_test)\n",
    "#     X_val = np.nan_to_num(X_val)\n",
    "    \n",
    "    \n",
    "    if training_type == 'classify':\n",
    "        y_train = y_train.values.reshape(-1,1)\n",
    "        y_val = torch.squeeze(torch.tensor(y_val.values.reshape(-1,1),dtype=torch.int64)).to(device)\n",
    "        dataset = MyDataset(X_train, y_train,training_type)\n",
    "        \n",
    "    elif training_type == 'regress' and regress_type == 'regress_center':\n",
    "        print('regress_center')\n",
    "        y_train_center_only = y_train.PoI_GT_centerLatAngle.values.reshape(-1,1)\n",
    "        y_val_center_only = torch.tensor(y_val.PoI_GT_centerLatAngle.values.reshape(-1,1),dtype=torch.float32).to(device)\n",
    "        dataset = MyDataset(X_train, y_train_center_only,training_type)\n",
    "    \n",
    "    elif regress_type == 'regress_facade':\n",
    "        print('regress_facade')\n",
    "        y_train_center_only = (y_train[['PoI_GT_visibleMinLatAngle','PoI_GT_visibleMaxLatAngle']].mean(axis=1)).values.reshape(-1,1)\n",
    "        y_val_center_only = torch.tensor((y_val[['PoI_GT_visibleMinLatAngle','PoI_GT_visibleMaxLatAngle']].mean(axis=1)).values.reshape(-1,1),dtype=torch.float32).to(device)\n",
    "        dataset = MyDataset(X_train, y_train_center_only,training_type)\n",
    "\n",
    "    #create dataset and generate dataloader\n",
    "    \n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, \n",
    "                             collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))\n",
    "\n",
    "    # Define Optimizer and Loss Function\n",
    "#     optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "    optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate)\n",
    "    \n",
    "\n",
    "    \n",
    "    if training_type == 'classify':\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "    elif training_type == 'regress':\n",
    "        loss_func = torch.nn.MSELoss()\n",
    "    \n",
    "    #saving checkpoints for continuing training (e.g., transfer learning)\n",
    "    \n",
    "    if not inference_only:\n",
    "    \n",
    "        if fine_tuning:\n",
    "            net, optimizer, start_epoch = load_ckp(fine_tune_ckp_path, net, optimizer)\n",
    "            print(start_epoch)\n",
    "\n",
    "        print('Training the Deep Learning network ...')\n",
    "\n",
    "\n",
    "\n",
    "        val_losses = []\n",
    "        train_losses = []\n",
    "\n",
    "\n",
    "        # initialize the early_stopping object\n",
    "        early_stopping = EarlyStopping(patience=40, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "        for epoch in range(number_epochs):\n",
    "            print(epoch)\n",
    "            avg_cost = []\n",
    "\n",
    "            net.train()\n",
    "            for i, (batch_X, batch_Y) in enumerate(data_loader):\n",
    "                X = Variable(batch_X)    \n",
    "                Y = Variable(batch_Y)\n",
    "                if training_type == 'classify':\n",
    "                    Y = torch.squeeze(Y)\n",
    "\n",
    "                optimizer.zero_grad() # <= initialization of the gradients\n",
    "\n",
    "                # forward propagation\n",
    "                prediction = net(X)\n",
    "    #             print(prediction.shape, Y.shape)\n",
    "                loss = loss_func(prediction, Y) # <= compute the loss function\n",
    "\n",
    "                # Backward propagation\n",
    "                loss.backward() # <= compute the gradient of the loss/cost function     \n",
    "                optimizer.step() # <= Update the gradients\n",
    "\n",
    "\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': net.state_dict(),\n",
    "                'optimizer': optimizer.state_dict()\n",
    "            }\n",
    "\n",
    "            if fine_tuning:\n",
    "                save_ckp(checkpoint, False, 'checkpoint_finetuned.pt')\n",
    "            else:\n",
    "                save_ckp(checkpoint, False, 'checkpoint_participant.pt')\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "    #         print('train loss:', loss.item())\n",
    "\n",
    "            net.eval() # prep model for evaluation\n",
    "            with torch.no_grad():\n",
    "    #             print(X_val)\n",
    "                X_val_trch = torch.tensor(X_val,dtype=torch.float32).to(device)\n",
    "    #             print(X_val_trch.shape)\n",
    "                prediction_val = net(X_val_trch)\n",
    "    #             print(prediction_val,y_val_center_only)\n",
    "                if training_type == 'classify':\n",
    "                    loss_val = loss_func(prediction_val, y_val)\n",
    "                elif training_type == 'regress':\n",
    "                    loss_val = loss_func(prediction_val, y_val_center_only)\n",
    "                val_losses.append(loss_val.item())\n",
    "    #             print('val loss:', loss_val.item())\n",
    "\n",
    "            # early_stopping needs the validation loss to check if it has decresed, \n",
    "            # and if it has, it will make a checkpoint of the current model\n",
    "            early_stopping(np.average(val_losses), net)\n",
    "            print(np.average(val_losses))\n",
    "            if early_stopping.early_stop:\n",
    "                save_ckp(checkpoint, True, 'checkpoint_earlystopping_full.pt')\n",
    "                print(\"Early stopping at Epoch \" + str(epoch))\n",
    "\n",
    "        print('Learning Finished!')\n",
    "\n",
    "        print('last train loss:', loss.item())\n",
    "        print('last val loss:', loss_val.item())\n",
    "\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(\"Training and Validation Loss\")\n",
    "        plt.plot(val_losses,label=\"val\")\n",
    "        plt.plot(train_losses,label=\"train\")\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "#     if inference_only:\n",
    "#         net.load_state_dict(torch.load(inference_ckp_path))\n",
    "#         net.eval()\n",
    "        \n",
    "    if inference_only:\n",
    "        \n",
    "        if \"earlystop\" in inference_ckp_path:\n",
    "            net.load_state_dict(torch.load(inference_ckp_path))\n",
    "        else:\n",
    "            net, optimizer, start_epoch = load_ckp(inference_ckp_path, net, optimizer)\n",
    "            print(start_epoch)\n",
    "            \n",
    "        net.eval()\n",
    "    \n",
    "    X_train_trch = torch.from_numpy(X_train).float().to(device)\n",
    "    np.savetxt('X_train.csv',X_train.reshape(X_train.shape[0], -1), delimiter=\",\")\n",
    "    print(X_train_trch.shape)\n",
    "    with torch.no_grad():\n",
    "        prediction_train = net(X_train_trch).cpu()\n",
    "    \n",
    "    if training_type == 'classify':\n",
    "        softmax = torch.exp(prediction_train).cpu()\n",
    "        prob = list(softmax.numpy())\n",
    "        predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "        # accuracy on training set\n",
    "        final_accuracy = accuracy_score(y_train, predictions)\n",
    "        print('Train Accuracy: ', final_accuracy)\n",
    "\n",
    "    elif training_type == 'regress':\n",
    "        print(prediction_train.shape)\n",
    "        prediction_np = prediction_train.detach().numpy().reshape(len(prediction_train))\n",
    "        \n",
    "        y_train['PoI_GT_centerLatAngle_predicted'] = prediction_np\n",
    "        \n",
    "        #generate list of indices for incremental learning, use K when loading to use\n",
    "        print(\"(((((((())))))))\")\n",
    "        print(y_train.columns)\n",
    "        y_train['prediction_error'] = (y_train['PoI_GT_centerLatAngle'] - y_train['PoI_GT_centerLatAngle_predicted']).abs()\n",
    "        temp_y_train = y_train.sort_values(by='prediction_error').reset_index(names='priority_index')\n",
    "        \n",
    "        # uncomment the following if you want to save a new priotirized examplers and move the file to the Data folder\n",
    "#         temp_y_train['priority_index'].to_csv('y_train_indeces_priotirized.csv')\n",
    "        print(\"(((((((())))))))\")\n",
    "        \n",
    "        final_accuracy = len(y_train[(y_train.PoI_GT_centerLatAngle_predicted > y_train.PoI_GT_minLatAngle) \n",
    "               & (y_train.PoI_GT_centerLatAngle_predicted < y_train.PoI_GT_maxLatAngle)]) / len(y_train)\n",
    "        print('Train Accuracy MRDE: ', final_accuracy)\n",
    "\n",
    "        final_accuracy = len(y_train[(y_train.PoI_GT_centerLatAngle_predicted > y_train.PoI_GT_visibleMinLatAngle) \n",
    "               & (y_train.PoI_GT_centerLatAngle_predicted < y_train.PoI_GT_visibleMaxLatAngle)]) / len(y_train)\n",
    "        print('Train Accuracy SegObj: ', final_accuracy)\n",
    "\n",
    "        final_accuracy = len(y_train[(y_train.PoI_GT_centerLatAngle_predicted > y_train.PoI_GT_adjustedMinLatAngle) \n",
    "               & (y_train.PoI_GT_centerLatAngle_predicted < y_train.PoI_GT_adjustedMaxLatAngle)]) / len(y_train)\n",
    "        print('Train Accuracy MinDT: ', final_accuracy)\n",
    "\n",
    "    X_val_trch = torch.from_numpy(X_val).float().to(device)\n",
    "    print(X_val_trch.shape)\n",
    "    with torch.no_grad():\n",
    "        prediction_val = net(X_val_trch).cpu()\n",
    "    \n",
    "    if training_type == 'classify':\n",
    "        softmax = torch.exp(prediction_val).cpu()\n",
    "        prob = list(softmax.numpy())\n",
    "        predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "        # accuracy on training set\n",
    "        final_accuracy = accuracy_score(y_val, predictions)\n",
    "        print('Val Accuracy: ', final_accuracy)\n",
    "\n",
    "    elif training_type == 'regress':\n",
    "        print(prediction_val.shape)\n",
    "        prediction_np = prediction_val.detach().numpy().reshape(len(prediction_val))\n",
    "\n",
    "        y_val['PoI_GT_centerLatAngle_predicted'] = prediction_np\n",
    "        final_accuracy = len(y_val[(y_val.PoI_GT_centerLatAngle_predicted > y_val.PoI_GT_minLatAngle) \n",
    "               & (y_val.PoI_GT_centerLatAngle_predicted < y_val.PoI_GT_maxLatAngle)]) / len(y_val)\n",
    "        print('Val Accuracy MRDE: ', final_accuracy)\n",
    "\n",
    "        final_accuracy = len(y_val[(y_val.PoI_GT_centerLatAngle_predicted > y_val.PoI_GT_visibleMinLatAngle) \n",
    "               & (y_val.PoI_GT_centerLatAngle_predicted < y_val.PoI_GT_visibleMaxLatAngle)]) / len(y_val)\n",
    "        print('Val Accuracy SegObj: ', final_accuracy)\n",
    "\n",
    "        final_accuracy = len(y_val[(y_val.PoI_GT_centerLatAngle_predicted > y_val.PoI_GT_adjustedMinLatAngle) \n",
    "               & (y_val.PoI_GT_centerLatAngle_predicted < y_val.PoI_GT_adjustedMaxLatAngle)]) / len(y_val)\n",
    "        print('Val Accuracy MinDT: ', final_accuracy)\n",
    "\n",
    "\n",
    "    X_test_trch = torch.from_numpy(X_test).float().to(device)\n",
    "    print(X_test_trch.shape)\n",
    "    with torch.no_grad():\n",
    "        prediction_test = net(X_test_trch).cpu()\n",
    "        \n",
    "        \n",
    "    if training_type == 'classify':\n",
    "        softmax = torch.exp(prediction_test).cpu()\n",
    "        prob = list(softmax.numpy())\n",
    "        predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "        # accuracy on test set\n",
    "        final_accuracy_test = accuracy_score(y_test, predictions)\n",
    "        print('Test Accuracy: ', final_accuracy_test)\n",
    "        \n",
    "        return final_accuracy_test\n",
    "\n",
    "    elif training_type == 'regress':\n",
    "        print(prediction_test.shape)\n",
    "        prediction_test_np = prediction_test.detach().numpy().reshape(len(prediction_test))\n",
    "\n",
    "        y_test['PoI_GT_centerLatAngle_predicted'] = prediction_test_np\n",
    "        final_accuracy_latangle = len(y_test[(y_test.PoI_GT_centerLatAngle_predicted > y_test.PoI_GT_minLatAngle) \n",
    "               & (y_test.PoI_GT_centerLatAngle_predicted < y_test.PoI_GT_maxLatAngle)]) / len(y_test)\n",
    "        print('Test Accuracy MRDE: ', final_accuracy_latangle)\n",
    "\n",
    "        final_accuracy_visiblelatangle = len(y_test[(y_test.PoI_GT_centerLatAngle_predicted > y_test.PoI_GT_visibleMinLatAngle) \n",
    "               & (y_test.PoI_GT_centerLatAngle_predicted < y_test.PoI_GT_visibleMaxLatAngle)]) / len(y_test)\n",
    "        print('Test Accuracy SegObj: ', final_accuracy_visiblelatangle)\n",
    "\n",
    "        final_accuracy_adjustedlatangle = len(y_test[(y_test.PoI_GT_centerLatAngle_predicted > y_test.PoI_GT_adjustedMinLatAngle) \n",
    "               & (y_test.PoI_GT_centerLatAngle_predicted < y_test.PoI_GT_adjustedMaxLatAngle)]) / len(y_test)\n",
    "        print('Test Accuracy MinDT: ', final_accuracy_adjustedlatangle)\n",
    "\n",
    "        return final_accuracy_latangle, final_accuracy_visiblelatangle, final_accuracy_adjustedlatangle\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afee1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../Data/\"\n",
    "mode = 'CNN' #CNN or LSTM or Transformer network\n",
    "training_type = 'regress' #classify or regress\n",
    "regress_type = 'regress_center' #regress_facade or regress_center\n",
    "batch_size = 128\n",
    "number_epochs = 20000\n",
    "learning_rate = 0.0001\n",
    "fine_tune_or_not = False\n",
    "fine_tune_ckp_path = \"checkpoint.pt\"\n",
    "inference_only = True\n",
    "# inference_ckp_path = \"checkpoint_participant.pt\"\n",
    "inference_ckp_path = \"checkpoint_earlystop.pt\"\n",
    "exemplar_ratio = 1 # 2 is half, 4 is quarter and so on while 0 is naive finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cf730de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_runs_concatenate(file_path1, file_path2 = False, exemplars_list_path = False):\n",
    "    \n",
    "    data = pd.read_csv(folder_path + file_path1).iloc[:,2:]\n",
    "    data['POIBuilding_new'] = data.POIBuilding_new - 1\n",
    "    current_participant = file_path1[-7:-4]\n",
    "  \n",
    "    #dropping test for the currently loaded variant and loading it from data2\n",
    "    data = data[~((data.Participant == 'P45') \n",
    "                      | (data.Participant == 'P75') \n",
    "                      | (data.Participant == 'P22') \n",
    "                      | (data.Participant == 'P40')\n",
    "                      | (data.Participant == 'P57')\n",
    "                      | (data.Participant == 'P74')\n",
    "                       )]\n",
    "\n",
    "    if file_path2 != False:\n",
    "        print('A second File Path was given for the test Data.')\n",
    "        print(file_path2)\n",
    "        data2 = pd.read_csv(folder_path + file_path2).iloc[:,2:]\n",
    "        data2['POIBuilding_new'] = data2.POIBuilding_new - 1\n",
    "        \n",
    "        #left is 22,45,74\n",
    "        #right is 40,57,75\n",
    "        #lessthan4 is 40,74,75\n",
    "        #morethan6 is 22,45,57\n",
    "        \n",
    "        test_data_index_in_IsNoise = data2[(\n",
    "                        (data2.Participant == 'P45') \n",
    "                      | (data2.Participant == 'P75') \n",
    "                      | (data2.Participant == 'P22') \n",
    "                      | (data2.Participant == 'P40')\n",
    "                      | (data2.Participant == 'P57')\n",
    "                      | (data2.Participant == 'P74')\n",
    "                     )].index.tolist()\n",
    "        \n",
    "        \n",
    "        if exemplars_list_path != False:\n",
    "            exemplars_temp = pd.read_csv(folder_path + exemplars_list_path).iloc[:,1:]\n",
    "            \n",
    "            if exemplar_ratio != 0:\n",
    "                exemplar_number = len(exemplars_temp) // exemplar_ratio\n",
    "                exemplars_list = exemplars_temp['priority_index'].iloc[:exemplar_number].tolist()\n",
    "                print(len(exemplars_list))\n",
    "#                 exemplars_list2 = exemplars_temp['priority_index'].iloc[-exemplar_number:].tolist()\n",
    "#                 exemplars_list.extend(exemplars_list2)\n",
    "                exemplars_list.extend(test_data_index_in_IsNoise)\n",
    "                print(len(exemplars_list))\n",
    "            elif exemplar_ratio == 0:\n",
    "                exemplars_list = test_data_index_in_IsNoise\n",
    "                print(len(exemplars_list))\n",
    "                \n",
    "            print(exemplars_list)\n",
    "            data2 = data2.iloc[exemplars_list]\n",
    "            \n",
    "        \n",
    "        data = pd.concat([data,data2])\n",
    "        \n",
    "        \n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data.reset_index(inplace=True)\n",
    "#     print(data)\n",
    "    #     print(data.columns)\n",
    "    print(\"#\"*80)\n",
    "\n",
    "    # ffill and bfill instead of replacing np.nan with zeros\n",
    "    data[[col for col in data.columns if 'PointingDirectionX_' in col]] = data[[col for col in data.columns if 'PointingDirectionX_' in col]].ffill(axis=1).bfill(axis=1)\n",
    "    data[[col for col in data.columns if 'PointingDirectionZ_' in col]] = data[[col for col in data.columns if 'PointingDirectionZ_' in col]].ffill(axis=1).bfill(axis=1)\n",
    "    data[[col for col in data.columns if 'HeadGazeDirectionX_' in col]] = data[[col for col in data.columns if 'HeadGazeDirectionX_' in col]].ffill(axis=1).bfill(axis=1)\n",
    "    data[[col for col in data.columns if 'HeadGazeDirectionZ_' in col]] = data[[col for col in data.columns if 'HeadGazeDirectionZ_' in col]].ffill(axis=1).bfill(axis=1)\n",
    "    data[[col for col in data.columns if 'HeadposeX_' in col]] = data[[col for col in data.columns if 'HeadposeX_' in col]].ffill(axis=1).bfill(axis=1)\n",
    "    data[[col for col in data.columns if 'HeadposeZ_' in col]] = data[[col for col in data.columns if 'HeadposeZ_' in col]].ffill(axis=1).bfill(axis=1)\n",
    "    data[[col for col in data.columns if 'GazeX_' in col]] = data[[col for col in data.columns if 'GazeX_' in col]].ffill(axis=1).bfill(axis=1)\n",
    "    data[[col for col in data.columns if 'GazeZ_' in col]] = data[[col for col in data.columns if 'GazeZ_' in col]].ffill(axis=1).bfill(axis=1)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    data_train = data[~(\n",
    "                        (data.Participant == 'P45') \n",
    "                      | (data.Participant == 'P75') \n",
    "                      | (data.Participant == 'P22') \n",
    "                      | (data.Participant == 'P40')\n",
    "                      | (data.Participant == 'P57')\n",
    "                      | (data.Participant == 'P74')\n",
    "                       )]\n",
    "    data_test = data[(\n",
    "                        (data.Participant == 'P45') \n",
    "                      | (data.Participant == 'P75') \n",
    "                      | (data.Participant == 'P22') \n",
    "                      | (data.Participant == 'P40')\n",
    "                      | (data.Participant == 'P57')\n",
    "                      | (data.Participant == 'P74')\n",
    "                     )]\n",
    "    \n",
    "    data_test = data_test[~(data_test.Participant == current_participant)]\n",
    "    \n",
    "#     print(data_train)\n",
    "#     print(data_test)\n",
    "    \n",
    "    data_length = len(data[(data.Participant == current_participant)])\n",
    "    print(data_length)\n",
    "    data_train_participant = data[(data.Participant == current_participant)].iloc[0:data_length//2]\n",
    "    data_test_participant = data[(data.Participant == current_participant)].iloc[data_length//2:]\n",
    "    \n",
    "#     print(data_train_participant)\n",
    "#     print(data_test_participant)\n",
    "    \n",
    "    data_train = pd.concat([data_train,data_train_participant])\n",
    "    data_test = pd.concat([data_test,data_test_participant])\n",
    "    \n",
    "    #inside distribution test set\n",
    "#     data_test = data_test_participant\n",
    "    #outside distribution test set\n",
    "    data_test = data_test[~(data_test.Participant == current_participant)]\n",
    "    \n",
    "#     print(data_train)\n",
    "#     print(data_test)\n",
    "    \n",
    "    \n",
    "#     input_columns = []\n",
    "#     input_columns.extend([col for col in data_test.columns if ('PointingDirectionX_' in col) or ('PointingDirectionZ_' in col)])\n",
    "#     input_columns.extend([col for col in data_test.columns if ('HeadGazeDirectionX_' in col) or ('HeadGazeDirectionZ_' in col)])\n",
    "#     input_columns.extend([col for col in data_test.columns if ('HeadposeX_' in col) or ('HeadposeZ_' in col)])\n",
    "#     input_columns.extend([col for col in data_test.columns if ('GazeX_' in col) or ('GazeZ_' in col)])\n",
    "\n",
    "    input_columns = [col for col in data_test.columns if ('X_' in col) or ('Z_' in col)]\n",
    "\n",
    "#     print(len(input_columns))\n",
    "#     print(data_train.columns)\n",
    "    \n",
    "    \n",
    "    if training_type == 'classify':\n",
    "    \n",
    "        all_runs_acc = []\n",
    "\n",
    "\n",
    "        for i in range(1):\n",
    "            \n",
    "            final_accuracy = main_to_run(data_train,data_test,input_columns,mode,training_type,number_epochs,batch_size,learning_rate,fine_tune_or_not,fine_tune_ckp_path,inference_only, inference_ckp_path, regress_type)\n",
    "            all_runs_acc.append(final_accuracy)\n",
    "\n",
    "        print(\"#\"*80)\n",
    "        print(\"#\"*80)\n",
    "        print(all_runs_acc)\n",
    "        print((np.asarray(all_runs_acc)).mean())\n",
    "        print(\"#\"*80)\n",
    "        print(\"#\"*80)\n",
    "    \n",
    "    elif training_type == 'regress':\n",
    "#     else:\n",
    "        \n",
    "        all_runs_latangle = []\n",
    "        all_runs_visiblelatangle = []\n",
    "        all_runs_adjustedlatangle = []\n",
    "\n",
    "        for i in range(1):\n",
    "            \n",
    "            final_accuracy_latangle, final_accuracy_visiblelatangle, final_accuracy_adjustedlatangle = main_to_run(data_train,data_test,input_columns,mode,training_type,number_epochs,batch_size,learning_rate,fine_tune_or_not,fine_tune_ckp_path,inference_only, inference_ckp_path, regress_type)\n",
    "            \n",
    "            all_runs_latangle.append(final_accuracy_latangle)\n",
    "            all_runs_visiblelatangle.append(final_accuracy_visiblelatangle)\n",
    "            all_runs_adjustedlatangle.append(final_accuracy_adjustedlatangle)\n",
    "\n",
    "        print(\"#\"*80)\n",
    "        print(\"#\"*80)\n",
    "        print(all_runs_latangle, all_runs_visiblelatangle, all_runs_adjustedlatangle)\n",
    "        print((np.asarray(all_runs_latangle)).mean(), (np.asarray(all_runs_visiblelatangle)).mean() ,(np.asarray(all_runs_adjustedlatangle)).mean())\n",
    "        print(\"#\"*80)\n",
    "        print(\"#\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a5c461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A second File Path was given for the test Data.\n",
      "/Data_based_on_Speech_onset.csv\n",
      "1732\n",
      "2241\n",
      "[1628, 2875, 4687, 3048, 152, 1380, 2847, 1353, 2235, 2701, 3261, 3726, 2859, 1587, 663, 792, 2842, 2865, 2502, 2367, 1208, 4494, 2767, 3773, 5012, 3720, 355, 3263, 2889, 935, 395, 772, 2650, 959, 3729, 1356, 4635, 2708, 656, 3810, 5019, 3060, 815, 2498, 737, 2471, 804, 3722, 4486, 4100, 4544, 925, 3528, 979, 1322, 1581, 1555, 1588, 4338, 3038, 1310, 3817, 3054, 2652, 1573, 1388, 3177, 2191, 1390, 1607, 461, 1633, 1305, 2854, 4596, 1438, 4999, 320, 4530, 4496, 3375, 124, 386, 1435, 4649, 3046, 956, 4989, 2188, 2661, 3363, 2829, 4985, 2826, 2436, 426, 169, 4665, 2512, 1820, 1560, 398, 814, 4046, 1568, 1571, 1366, 1424, 1516, 572, 383, 3611, 2803, 2239, 1487, 2524, 4031, 3206, 2173, 1311, 2772, 4106, 3842, 2641, 3707, 3058, 938, 4324, 3191, 321, 957, 4414, 407, 2462, 4376, 774, 3100, 3985, 93, 399, 1006, 4519, 4489, 3179, 765, 2185, 3784, 917, 1609, 920, 4491, 4972, 276, 2042, 703, 4284, 805, 2463, 1352, 3203, 2204, 322, 952, 5041, 1111, 3196, 4275, 4608, 4103, 1592, 2194, 4645, 1335, 3482, 2822, 2643, 4326, 1316, 653, 1583, 3245, 930, 1719, 113, 1538, 2494, 3020, 1602, 4080, 1370, 1383, 416, 458, 1495, 1144, 1426, 3070, 4511, 4267, 1622, 1598, 3047, 3606, 5022, 2529, 3873, 791, 1433, 3552, 5001, 719, 445, 2824, 2452, 1327, 1527, 1465, 2881, 1302, 718, 1667, 1142, 3068, 942, 4655, 3248, 446, 2687, 3534, 4988, 3598, 313, 2858, 1531, 3462, 4449, 2031, 4480, 2028, 721, 3991, 2811, 781, 4580, 3195, 448, 3695, 4021, 3073, 879, 3980, 967, 4010, 3042, 3176, 4164, 4575, 2253, 1498, 3899, 4581, 2843, 1314, 2206, 4512, 1296, 1271, 301, 676, 2668, 1360, 4455, 2056, 945, 3201, 444, 33, 150, 2840, 394, 3244, 2638, 1566, 1525, 2519, 1362, 159, 3092, 4620, 3589, 3535, 994, 3920, 3490, 3995, 2880, 4302, 2487, 1572, 757, 3603, 4670, 1509, 4059, 1574, 768, 4977, 747, 1313, 943, 1391, 4456, 812, 1499, 2693, 2508, 1718, 2654, 3849, 1367, 4014, 3850, 2887, 949, 3255, 1347, 130, 2509, 3184, 2861, 2823, 3209, 125, 4534, 750, 4653, 4087, 3872, 128, 3190, 711, 5040, 2868, 1595, 2200, 3754, 2673, 4044, 998, 4458, 4254, 1007, 2535, 1715, 3823, 3705, 4597, 4072, 3979, 650, 2468, 2079, 144, 3198, 1359, 2706, 4663, 2087, 181, 5015, 3220, 3187, 712, 1382, 4482, 3556, 3767, 5014, 4971, 1623, 4501, 1476, 392, 948, 1484, 1422, 4929, 678, 919, 3713, 1081, 973, 2030, 4615, 1552, 4274, 3062, 3041, 813, 4034, 3453, 795, 4646, 2888, 2383, 4052, 3192, 4523, 4047, 2658, 4618, 2696, 754, 761, 289, 1749, 2703, 391, 4524, 969, 962, 1625, 3395, 3891, 3233, 3626, 2059, 4097, 4024, 2489, 1796, 1343, 2814, 4318, 3226, 2645, 2820, 5047, 3440, 4506, 3478, 3448, 4173, 4968, 2855, 4876, 1193, 1557, 3808, 4549, 2809, 697, 3012, 4098, 664, 3605, 78, 3884, 981, 4057, 3224, 3001, 4470, 858, 1349, 2848, 927, 2898, 379, 2860, 541, 137, 4174, 2258, 1580, 2873, 2813, 3180, 762, 1727, 4987, 3063, 4288, 2050, 3868, 4978, 1611, 1301, 1524, 3181, 3818, 3638, 1374, 2700, 3359, 4880, 2530, 3494, 1423, 2496, 758, 1569, 3725, 803, 2664, 2817, 1194, 1463, 4006, 3030, 946, 2466, 4611, 3210, 607, 3225, 3766, 926, 4648, 2538, 3700, 1368, 2539, 3777, 1624, 4582, 978, 2686, 3621, 3393, 3848, 1514, 3067, 4319, 611, 1494, 4027, 4666, 1351, 2649, 4457, 4583, 2877, 3464, 359, 3249, 3590, 2409, 92, 3504, 3757, 992, 3178, 4652, 821, 2874, 3232, 1540, 3843, 5018, 1596, 3222, 783, 1512, 4563, 1530, 4673, 2827, 1618, 1547, 726, 2592, 3002, 147, 4352, 2467, 4221, 780, 2517, 1336, 4444, 3739, 2198, 3040, 4079, 327, 1523, 535, 2223, 1456, 3530, 2828, 3197, 3032, 975, 810, 3719, 3835, 432, 2520, 1328, 1619, 1372, 2812, 5032, 2156, 2846, 3044, 4003, 3839, 4298, 2492, 4463, 1502, 4984, 4994, 4287, 732, 490, 5016, 3791, 1636, 4026, 1292, 4304, 2894, 2691, 2201, 2818, 2862, 1050, 174, 953, 3990, 1010, 2884, 1594, 4589, 3799, 4982, 1632, 1613, 4996, 2542, 3869, 140, 543, 1513, 435, 2892, 3858, 2849, 3455, 1324, 4626, 2020, 2754, 4177, 2184, 3247, 3234, 1544, 2882, 4887, 4217, 1479, 4357, 2164, 122, 4311, 3803, 341, 2816, 5008, 3029, 2491, 2879, 3645, 332, 1563, 5020, 3141, 2825, 3994, 4236, 3561, 1470, 2999, 990, 1160, 3024, 3006, 2590, 1593, 4493, 1584, 4502, 4075, 3214, 2832, 4306, 1306, 2473, 4640, 621, 4685, 1804, 4012, 2856, 2453, 993, 1570, 3436, 2195, 665, 3697, 2105, 779, 1726, 786, 947, 2804, 977, 782, 1485, 3549, 101, 4939, 4970, 2897, 950, 4197, 9, 2209, 1638, 2808, 2181, 1521, 390, 4651, 4339, 4507, 980, 3016, 4054, 3240, 69, 3783, 3684, 385, 2269, 367, 3676, 1483, 766, 691, 3529, 2459, 2631, 1735, 4301, 5028, 1030, 1515, 105, 937, 1497, 1332, 2058, 2434, 4997, 4280, 479, 753, 4454, 1585, 1481, 652, 4990, 3059, 2493, 2533, 3770, 1539, 4240, 2771, 4333, 1610, 509, 4312, 2837, 337, 3801, 2639, 2646, 2207, 4516, 400, 4334, 4567, 1005, 403, 3845, 777, 3193, 553, 4270, 778, 4099, 3536, 1520, 4325, 3607, 1526, 4566, 2536, 3071, 2472, 4053, 2036, 3544, 1369, 2819, 1561, 2689, 3548, 4453, 1056, 817, 818, 3977, 4473, 3018, 3630, 4688, 2525, 4038, 4285, 4262, 1522, 4545, 3007, 4644, 3772, 759, 2053, 3435, 2821, 3854, 3816, 649, 1478, 3008, 119, 936, 822, 896, 3441, 735, 3066, 3238, 3243, 4621, 1626, 4269, 3503, 3487, 4613, 485, 2864, 157, 1529, 966, 4093, 449, 2669, 1319, 1378, 916, 1304, 3894, 1110, 4660, 3867, 970, 4690, 2511, 5044, 2470, 483, 456, 995, 3512, 3915, 305, 2024, 447, 729, 1615, 1630, 501, 2062, 3231, 982, 4036, 1186, 3168, 1542, 764, 4295, 3003, 2025, 738, 4487, 3227, 742, 2385, 523, 2676, 3797, 1333, 4393, 4539, 3074, 396, 2707, 2632, 4159, 3253, 3996, 2699, 4478, 599, 2526, 4091, 752, 4606, 3532, 1492, 1519, 3939, 1769, 2844, 3642, 4070, 3480, 3904, 4967, 4011, 2552, 4541, 3578, 3887, 670, 486, 4445, 2123, 1518, 3254, 3864, 3886, 906, 606, 4194, 2893, 4418, 4162, 647, 3893, 2683, 1339, 968, 4342, 716, 3392, 1002, 3662, 5045, 3437, 4691, 3221, 3246, 3043, 1477, 4095, 3241, 801, 1614, 696, 2867, 4642, 1634, 4417, 1350, 4292, 3216, 3200, 755, 1503, 3938, 4547, 709, 304, 1825, 2090, 984, 2477, 2677, 4479, 1732, 2748, 1617, 2670, 3815, 1549, 1491, 3488, 2260, 3856, 3573, 2534, 3517, 2423, 3844, 4157, 3892, 819, 4286, 2997, 1008, 4495, 4622, 963, 1021, 1464, 3045, 4321, 3228, 4441, 3587, 3459, 3862, 3883, 3033, 3186, 273, 800, 4061, 2799, 2694, 3397, 4668, 3861, 3840, 2246, 412, 1616, 1294, 1371, 3612, 2503, 4643, 1145, 4522, 710, 4508, 527, 1408, 2690, 1187, 2518, 280, 3104, 1346, 4678, 288, 4233, 2505, 4437, 2885, 3260, 1627, 4425, 3256, 2465, 3656, 4639, 4085, 1751, 4472, 3710, 4273, 787, 4633, 1591, 438, 4616, 1995, 1299, 530, 300, 3582, 1496, 1377, 1790, 3900, 877, 2016, 342, 2501, 3173, 1798, 1637, 4175, 5039, 4161, 4062, 5036, 1629, 4056, 1245, 1373, 3866, 1550, 1043, 1345, 348, 1286, 3876, 110, 4178, 4258, 929, 3933, 419, 3885, 3396, 1467, 3015, 1032, 2218, 4268, 393, 1279, 4307, 3199, 1320, 655, 999, 1827, 3672, 2764, 2227, 4526, 3591, 2876, 5013, 1489, 4427, 420, 2478, 2637, 3961, 3667, 3502, 1460, 2886, 951, 960, 798, 1603, 3830, 3733, 1586, 4499, 3413, 3988, 2850, 3975, 4015, 4981, 2537, 985, 1321, 2187, 2410, 5011, 2500, 771, 1389, 2870, 862, 4975, 3616, 4966, 422, 3594, 4025, 4689, 4682, 2543, 1809, 1337, 802, 4213, 4158, 3218, 1621, 1416, 940, 4661, 662, 3819, 1355, 914, 103, 2564, 964, 2777, 2644, 3117, 3230, 3090, 91, 2734, 1537, 5000, 4603, 1009, 4156, 5031, 4264, 3416, 3712, 3380, 2891, 4488, 3880, 1738, 1605, 477, 1536, 2787, 2532, 4946, 3457, 314, 3670, 3987, 3584, 1754, 4659, 4481, 4209, 3895, 4440, 3175, 4529, 450, 2704, 2647, 2202, 4662, 4431, 4395, 3827, 1308, 5005, 4693, 4196, 2666, 1590, 2513, 4619, 1384, 1042, 785, 349, 2793, 4405, 2414, 3077, 736, 369, 2060, 2257, 751, 1792, 3608, 4247, 4483, 4309, 1736, 3825, 3251, 3794, 3881, 1810, 809, 4028, 4674, 109, 3694, 4315, 2240, 4094, 3855, 4241, 2759, 763, 2114, 3452, 179, 4890, 2475, 1011, 840, 2786, 4667, 3112, 1631, 4329, 3906, 2454, 3052, 1640, 3771, 3257, 1070, 3026, 3863, 1472, 4394, 1344, 2199, 1188, 2216, 3871, 1788, 1791, 845, 3182, 2461, 3882, 1782, 1578, 806, 3116, 1750, 3057, 1510, 1601, 1589, 631, 3834, 286, 411, 4980, 2245, 3428, 939, 1697, 4610, 3833, 3468, 1723, 3788, 2642, 3483, 3986, 1814, 2398, 3444, 4435, 354, 4927, 648, 741, 3852, 2231, 3805, 2805, 4000, 3554, 634, 3905, 1657, 2254, 3522, 3049, 1620, 3741, 4231, 808, 4940, 996, 3148, 4612, 363, 2688, 3617, 4343, 2224, 1364, 3822, 1758, 1721, 493, 3146, 1819, 4664, 433, 1778, 2205, 3367, 3164, 3479, 3064, 402, 3099, 4250, 2460, 1459, 1215, 3902, 2838, 4930, 3463, 4160, 651, 2635, 2810, 3259, 4694, 2985, 4609, 2497, 1289, 2259, 1053, 3838, 2464, 1173, 1717, 3465, 3025, 3223, 1789, 382, 4371, 1022, 1575, 3911, 4230, 4278, 4182, 1752, 1762, 1763, 4090, 4327, 2215, 4562, 3610, 1604, 1822, 2495, 3681, 4683, 961, 1800, 3595, 117, 1757, 1073, 965, 3829, 1091, 2190, 3789, 4004, 4367, 4294, 271, 3131, 3824, 3781, 3615, 415, 3183, 4397, 3928, 3831, 2222, 3075, 1046, 2681, 739, 4416, 3456, 344, 1338, 2230, 1720, 2760, 4299, 1794, 3949, 1807, 4675, 368, 1743, 2510, 4684, 1799, 1734, 1553, 4617, 3546, 1783, 1608, 476, 1722, 3780, 2234, 2450, 1710, 4375, 2710, 2427, 1766, 4155, 571, 285, 1784, 2271, 3955, 4185, 2977, 799, 2047, 1756, 4337, 4404, 760, 2515, 4281, 436, 1748, 4222, 1180, 4172, 328, 4400, 928, 4671, 944, 2192, 1770, 4184, 1031, 4243, 3982, 442, 4300, 1805, 1067, 1773, 4697, 507, 2226, 3723, 1733, 1291, 2217, 146, 604, 4320, 4211, 3875, 1365, 3145, 3903, 4341, 2248, 1793, 2037, 3698, 517, 1813, 4868, 3467, 3978, 910, 1759, 3492, 4263, 2221, 2208, 542, 1334, 4364, 4259, 410, 3917, 1318, 3832, 2220, 1767, 4407, 4188, 743, 4422, 3069, 1797, 4420, 4677, 2233, 2212, 1068, 4328, 1787, 3219, 1020, 1317, 4224, 797, 2653, 1821, 1772, 3976, 418, 4913, 1815, 2761, 1501, 2228, 4936, 4389, 4016, 1830, 1361, 3473, 351, 4261, 4406, 3918, 4232, 1083, 2444, 2476, 1074, 4234, 1780, 4193, 955, 1059, 484, 3846, 1028, 2531, 2196, 4696, 770, 1290, 1812, 1071, 4235, 2213, 830, 2969, 4372, 1985, 2225, 1429, 2219, 4076, 4181, 3756, 4246, 2830, 524, 4289, 4186, 121, 3491, 1744, 2490, 4229, 686, 986, 4283, 149, 1348, 1753, 4069, 492, 1084, 4096, 4686, 1079, 3567, 2229, 4071, 1695, 389, 401, 2933, 1001, 1387, 1325, 1331, 2866, 1642, 1795, 740, 3702, 4191, 4271, 3916, 4484, 1779, 4426, 3477, 3458, 310, 4050, 3981, 2210, 2211, 4293, 3076, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326, 3327, 3328, 3329, 3330, 3331, 3332, 3333, 3334, 3335, 3336, 3337, 3338, 3339, 3340, 3341, 3342, 3343, 3344, 3345, 3346, 3347, 4700, 4701, 4702, 4703, 4704, 4705, 4706, 4707, 4708, 4709, 4710, 4711, 4712, 4713, 4714, 4715, 4716, 4717, 4718, 4719, 4720, 4721, 4722, 4723, 4724, 4725, 4726, 4727, 4728, 4729, 4730, 4731, 4732, 4733, 4734, 4735, 4736, 4737, 4738, 4739, 4740, 4741, 4742, 4743, 4744, 4745, 4746, 4747, 4748, 4749, 4750, 4751, 4752, 4753, 4754, 4755, 4756, 4757, 4758, 4759, 4760, 4761, 4762, 4763, 4764, 4765, 4766, 4767, 4768, 4769, 4770, 4771, 4772, 4773, 4774, 4775, 4776, 4777, 4778, 4779, 4780, 4781, 4782, 4783, 4784, 4785, 4786, 4787, 4788, 4789, 4790, 4791, 4792, 4793, 4794, 4795, 4796, 4797, 4798, 4799, 4800, 4801, 4802, 4803, 4804, 4805, 4806, 4807, 4808, 4809, 4810, 4811, 4812, 4813, 4814, 4815, 4816, 4817, 4818, 4819, 4820, 4821, 4822, 4823, 4824, 4825, 4826, 4827, 4828, 4829, 4830, 4831, 4832, 4833, 4834, 4835, 4836, 4837, 4838, 4839, 4840, 4841, 4842, 4843, 4844, 4845, 4846, 4847, 4848, 4849, 4850, 4851, 4852, 4853, 4854, 4855, 4856, 4857, 4858, 4859, 4860, 4861, 4862, 4863, 4864, 4865, 4866]\n",
      "################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "(1753, 8, 20) (232, 8, 20) (1753, 7) (232, 7)\n",
      "(1542, 8, 20) (211, 8, 20) (232, 8, 20) (1542, 7) (211, 7) (232, 7)\n",
      "################################################################################\n",
      "NetCNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv1d(8, 64, kernel_size=(2,), stride=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (layer1_1): Sequential(\n",
      "    (0): Conv1d(64, 16, kernel_size=(2,), stride=(1,))\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv1d(16, 8, kernel_size=(3,), stride=(1,))\n",
      "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=48, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (layer3_1): Sequential(\n",
      "    (0): Linear(in_features=48, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (layer4): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n",
      "cuda:0\n",
      "regress_center\n",
      "torch.Size([1542, 8, 20])\n",
      "torch.Size([1542, 1])\n",
      "(((((((())))))))\n",
      "Index(['PoI_GT_centerLatAngle', 'PoI_GT_visibleMinLatAngle',\n",
      "       'PoI_GT_visibleMaxLatAngle', 'PoI_GT_minLatAngle', 'PoI_GT_maxLatAngle',\n",
      "       'PoI_GT_adjustedMinLatAngle', 'PoI_GT_adjustedMaxLatAngle',\n",
      "       'PoI_GT_centerLatAngle_predicted'],\n",
      "      dtype='object')\n",
      "(((((((())))))))\n",
      "Train Accuracy MRDE:  0.7217898832684825\n",
      "Train Accuracy SegObj:  0.5110246433203631\n",
      "Train Accuracy MinDT:  0.5784695201037614\n",
      "torch.Size([211, 8, 20])\n",
      "torch.Size([211, 1])\n",
      "Val Accuracy MRDE:  0.7440758293838863\n",
      "Val Accuracy SegObj:  0.5023696682464455\n",
      "Val Accuracy MinDT:  0.5497630331753555\n",
      "torch.Size([232, 8, 20])\n",
      "torch.Size([232, 1])\n",
      "Test Accuracy MRDE:  0.7198275862068966\n",
      "Test Accuracy SegObj:  0.3448275862068966\n",
      "Test Accuracy MinDT:  0.3922413793103448\n",
      "################################################################################\n",
      "################################################################################\n",
      "[0.7198275862068966] [0.3448275862068966] [0.3922413793103448]\n",
      "0.7198275862068966 0.3448275862068966 0.3922413793103448\n",
      "################################################################################\n",
      "################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185115/1042994434.py:317: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test['PoI_GT_centerLatAngle_predicted'] = prediction_test_np\n"
     ]
    }
   ],
   "source": [
    "multiple_runs_concatenate('Per_Participant/Data_based_on_Speech_onset_P74.csv','/Data_based_on_Speech_onset.csv','y_train_indeces_priotirized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a3302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
